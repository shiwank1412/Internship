{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question:- 1 Write a python program which searches all the product under a particular product from www.amazon.in.\n",
    "The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for\n",
    "guitars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b06ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def search_product(product):\n",
    "  # Format the search query\n",
    "  search_query = product.replace(' ', '+')\n",
    "\n",
    "  # Send a GET request to Amazon.in search page\n",
    "  url = f'https://www.amazon.in/s?k={search_query}'\n",
    "  response = requests.get(url)\n",
    "\n",
    "  # Parse the HTML content using BeautifulSoup\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "  # Find all the product elements on the page\n",
    "  products = soup.find_all('div', {'data-component-type': 's-search-result'})\n",
    "\n",
    "  # Iterate over the products and extract relevant information\n",
    "  for product in products:\n",
    "  # Extract the product title\n",
    "  title = product.find('span', {'class': 'a-size-medium'}).text.strip()\n",
    "\n",
    "  # Extract the product price\n",
    "  price = product.find('span', {'class': 'a-price-whole'}).text.strip()\n",
    "\n",
    "  # Extract the product rating\n",
    "  rating = product.find('span', {'class': 'a-icon-alt'}).text.strip()\n",
    "http://localhost:8889/notebooks/Untitled6.ipynb?kernel_name=python3#\n",
    "  # Print the product information\n",
    "  print(f'Title: {title}')\n",
    "  print(f'Price: {price}')\n",
    "  print(f'Rating: {rating}')\n",
    "  print('---')\n",
    "\n",
    "# Take user input for the product to search\n",
    "product = input('Enter the product to search: ')\n",
    "\n",
    "# Call the search_product function with the user input\n",
    "search_product(product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ce96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question :- 2 In the above question, now scrape the following details of each product listed in first 3 pages of your search\n",
    "results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then\n",
    "scrape all the products available under that product name. Details to be scraped are: \"Brand\n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and\n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcaf932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question :-3 Write a python program to access the search bar and search button on images.google.com and scrape 10\n",
    "images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5596ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "# Set up the Chrome driver\n",
    "driver = webdriver.Chrome('path_to_chromedriver')\n",
    "\n",
    "# Open images.google.com\n",
    "driver.get('https://images.google.com')\n",
    "\n",
    "# Define the keywords\n",
    "keywords = ['fruits', 'cars', 'Machine Learning', 'Guitar', 'Cakes']\n",
    "\n",
    "# Scrape 10 images for each keyword\n",
    "for keyword in keywords:\n",
    "  # Find the search bar element and enter the keyword\n",
    "  search_bar = driver.find_element_by_name('q')\n",
    "  search_bar.clear()\n",
    "  search_bar.send_keys(keyword)\n",
    "  \n",
    "  # Find the search button element and click it\n",
    "  search_button = driver.find_element_by_css_selector('button[type=\"submit\"]')\n",
    "  search_button.click()\n",
    "  \n",
    "  # Wait for the page to load\n",
    "  time.sleep(2)\n",
    "  \n",
    "  # Scroll down to load more images\n",
    "  driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "  time.sleep(2)\n",
    "  \n",
    "  # Scrape the images\n",
    "  images = driver.find_elements_by_css_selector('img.rg_i')\n",
    "  for i in range(10):\n",
    "  image_url = images[i].get_attribute('src')\n",
    "  print(f\"Scraped image {i+1} for keyword '{keyword}': {image_url}\")\n",
    "  \n",
    "  # Go back to the search page\n",
    "  driver.execute_script(\"window.history.go(-1)\")\n",
    "  time.sleep(2)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cca7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question :-4 Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand\n",
    "Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the\n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5527fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Function to scrape smartphone details\n",
    "def scrape_smartphones():\n",
    "  url = \"https://www.flipkart.com/search?q=smartphone\"  # Replace \"smartphone\" with your desired search query\n",
    "  response = requests.get(url)\n",
    "  soup = BeautifulSoup(response.content, 'html.parser')\n",
    "  \n",
    "  smartphones = []\n",
    "  \n",
    "  results = soup.find_all('div', {'class': '_1AtVbE'})\n",
    "  \n",
    "  for result in results:\n",
    "  details = {}\n",
    "  \n",
    "  # Extracting details from each search result\n",
    "  details['Brand Name'] = result.find('div', {'class': '_4rR01T'}).text\n",
    "  details['Smartphone Name'] = result.find('a', {'class': 'IRpwTa'}).text\n",
    "  details['Colour'] = result.find('div', {'class': '_2WkVRV'}).text\n",
    "  details['RAM'] = result.find('ul', {'class': '_1xgFaf'}).find_all('li')[0].text\n",
    "  details['Storage(ROM)'] = result.find('ul', {'class': '_1xgFaf'}).find_all('li')[1].text\n",
    "  details['Primary Camera'] = result.find('ul', {'class': '_1xgFaf'}).find_all('li')[2].text\n",
    "  details['Secondary Camera'] = result.find('ul', {'class': '_1xgFaf'}).find_all('li')[3].text\n",
    "  details['Display Size'] = result.find('ul', {'class': '_1xgFaf'}).find_all('li')[4].text\n",
    "  details['Battery Capacity'] = result.find('ul', {'class': '_1xgFaf'}).find_all('li')[5].text\n",
    "  details['Price'] = result.find('div', {'class': '_30jeq3 _1_WHN1'}).text\n",
    "  details['Product URL'] = \"https://www.flipkart.com\" + result.find('a', {'class': 'IRpwTa'})['href']\n",
    "  \n",
    "  smartphones.append(details)\n",
    "  \n",
    "  return smartphones\n",
    "\n",
    "# Scrape smartphone details\n",
    "smartphones = scrape_smartphones()\n",
    "\n",
    "# Create dataframe from the scraped details\n",
    "df = pd.DataFrame(smartphones)\n",
    "\n",
    "# Replace missing details with \"-\"\n",
    "df.fillna(\"-\", inplace=True)\n",
    "\n",
    "# Save dataframe to CSV\n",
    "df.to_csv('smartphones.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f34a927",
   "metadata": {},
   "source": [
    "Question:-5 . Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_coordinates(city):\n",
    "  # Format the search query\n",
    "  query = f\"google maps {city} coordinates\"\n",
    "\n",
    "  # Send a GET request to Google search\n",
    "  response = requests.get(f\"https://www.google.com/search?q={query}\")\n",
    "\n",
    "  # Parse the HTML response using BeautifulSoup\n",
    "  soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "  # Find the element containing the coordinates\n",
    "  result = soup.find(\"div\", class_=\"BNeawe iBp4i AP7Wnd\")\n",
    "\n",
    "  # Extract the coordinates from the element\n",
    "  coordinates = result.text.split(\",\")\n",
    "  latitude = coordinates[0].strip()\n",
    "  longitude = coordinates[1].strip()\n",
    "\n",
    "  return latitude, longitude\n",
    "\n",
    "# Example usage\n",
    "city = \"New York\"\n",
    "latitude, longitude = get_coordinates(city)\n",
    "print(f\"The coordinates of {city} are: Latitude - {latitude}, Longitude - {longitude}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa343908",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question:-6 Write a program to scrap all the available details of best gaming laptops from digit.in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa58519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "# Set up the WebDriver\n",
    "driver = webdriver.Chrome('path_to_chromedriver')\n",
    "\n",
    "# Open the website\n",
    "driver.get('https://www.digit.in/')\n",
    "\n",
    "# Search for gaming laptops\n",
    "search_bar = driver.find_element_by_id('searchDiv')\n",
    "search_bar.send_keys('gaming laptops')\n",
    "search_bar.submit()\n",
    "\n",
    "# Wait for the search results to load\n",
    "time.sleep(2)\n",
    "\n",
    "# Scrape the details\n",
    "laptop_elements = driver.find_elements_by_class_name('searchPage')\n",
    "laptop_details = []\n",
    "\n",
    "for laptop in laptop_elements:\n",
    "  name = laptop.find_element_by_class_name('searchProductTitle').text\n",
    "  price = laptop.find_element_by_class_name('searchPrice').text\n",
    "  specifications = laptop.find_element_by_class_name('searchSpec').text\n",
    "  \n",
    "  laptop_details.append({\n",
    "  'Name': name,\n",
    "  'Price': price,\n",
    "  'Specifications': specifications\n",
    "  })\n",
    "\n",
    "# Print the scraped details\n",
    "for laptop in laptop_details:\n",
    "  print(laptop)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7020a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question :7 Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped:\n",
    "“Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c866253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the Forbes website\n",
    "url = \"https://www.forbes.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing the billionaire details\n",
    "table = soup.find(\"table\", class_=\"table\")\n",
    "\n",
    "# Find all the rows in the table\n",
    "rows = table.find_all(\"tr\")\n",
    "\n",
    "# Iterate over each row and extract the required details\n",
    "for row in rows:\n",
    "  # Find the columns in each row\n",
    "  columns = row.find_all(\"td\")\n",
    "  \n",
    "  # Extract the required details from the columns\n",
    "  rank = columns[0].text.strip()\n",
    "  name = columns[1].text.strip()\n",
    "  net_worth = columns[2].text.strip()\n",
    "  age = columns[3].text.strip()\n",
    "  citizenship = columns[4].text.strip()\n",
    "  source = columns[5].text.strip()\n",
    "  industry = columns[6].text.strip()\n",
    "  \n",
    "  # Print the extracted details\n",
    "  print(\"Rank:\", rank)\n",
    "  print(\"Name:\", name)\n",
    "  print(\"Net worth:\", net_worth)\n",
    "  print(\"Age:\", age)\n",
    "  print(\"Citizenship:\", citizenship)\n",
    "  print(\"Source:\", source)\n",
    "  print(\"Industry:\", industry)\n",
    "  print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce66d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question:-8 Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted\n",
    "from any YouTube Video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26549279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "# Set up the WebDriver\n",
    "driver = webdriver.Chrome('path_to_chromedriver')  # Replace with the path to your WebDriver executable\n",
    "\n",
    "# Open the YouTube video\n",
    "video_url = 'https://www.youtube.com/watch?v=your_video_id'  # Replace with the URL of the YouTube video\n",
    "driver.get(video_url)\n",
    "\n",
    "# Scroll to load comments\n",
    "scroll_pause_time = 2  # Adjust the pause time as needed\n",
    "scrolls = 10  # Adjust the number of scrolls as needed\n",
    "\n",
    "for _ in range(scrolls):\n",
    "  driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "  time.sleep(scroll_pause_time)\n",
    "\n",
    "# Extract comments, upvotes, and time\n",
    "comments = driver.find_elements_by_xpath('//yt-formatted-string[@id=\"content-text\"]')\n",
    "upvotes = driver.find_elements_by_xpath('//span[@id=\"vote-count-middle\"]')\n",
    "times = driver.find_elements_by_xpath('//a[@class=\"yt-simple-endpoint style-scope yt-formatted-string\"]')\n",
    "\n",
    "# Store the extracted data\n",
    "extracted_data = []\n",
    "for comment, upvote, time in zip(comments, upvotes, times):\n",
    "  extracted_data.append({\n",
    "  'comment': comment.text,\n",
    "  'upvote': upvote.text,\n",
    "  'time': time.text\n",
    "  })\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()\n",
    "\n",
    "# Print the extracted data\n",
    "for data in extracted_data:\n",
    "  print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb03370",
   "metadata": {},
   "outputs": [],
   "source": [
    "Question:-9 Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in\n",
    "“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overall\n",
    "reviews, privates from price, dorms from price, facilities and property description. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb0657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Send a GET request to the website\n",
    "url = \"https://www.hostelworld.com/hostels/London\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find all the hostel containers\n",
    "hostels = soup.find_all(\"div\", class_=\"fabresult\")\n",
    "\n",
    "# Iterate over each hostel container and extract the required information\n",
    "for hostel in hostels:\n",
    "  # Extract hostel name\n",
    "  name = hostel.find(\"h2\", class_=\"fabresult-title\").text.strip()\n",
    "  \n",
    "  # Extract distance from city centre\n",
    "  distance = hostel.find(\"span\", class_=\"distance\").text.strip()\n",
    "  \n",
    "  # Extract ratings\n",
    "  ratings = hostel.find(\"div\", class_=\"rating\").text.strip()\n",
    "  \n",
    "  # Extract total reviews\n",
    "  total_reviews = hostel.find(\"div\", class_=\"reviews\").text.strip()\n",
    "  \n",
    "  # Extract overall reviews\n",
    "  overall_reviews = hostel.find(\"div\", class_=\"overall\").text.strip()\n",
    "  \n",
    "  # Extract privates from price\n",
    "  privates_price = hostel.find(\"div\", class_=\"price-col\").find(\"div\", class_=\"price\").text.strip()\n",
    "  \n",
    "  # Extract dorms from price\n",
    "  dorms_price = hostel.find(\"div\", class_=\"price-col\").find(\"div\", class_=\"price\").find_next_sibling(\"div\", class_=\"price\").text.strip()\n",
    "  \n",
    "  # Extract facilities\n",
    "  facilities = hostel.find(\"div\", class_=\"facilities\").text.strip()\n",
    "  \n",
    "  # Extract property description\n",
    "  description = hostel.find(\"div\", class_=\"description\").text.strip()\n",
    "  \n",
    "  # Print the extracted information\n",
    "  print(\"Hostel Name:\", name)\n",
    "  print(\"Distance from City Centre:\", distance)\n",
    "  print(\"Ratings:\", ratings)\n",
    "  print(\"Total Reviews:\", total_reviews)\n",
    "  print(\"Overall Reviews:\", overall_reviews)\n",
    "  print(\"Privates from Price:\", privates_price)\n",
    "  print(\"Dorms from Price:\", dorms_price)\n",
    "  print(\"Facilities:\", facilities)\n",
    "  print(\"Property Description:\", description)\n",
    "  print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
